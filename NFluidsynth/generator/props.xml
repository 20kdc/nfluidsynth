<doc>

<table border="1" cellspacing="0">
  <caption>Table 1. Synthesizer settings</caption>
  <tr>
    <td>synth.audio-channels</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>1-128</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>By default, the synthesizer outputs a single stereo signal.
    Using this option, the synthesizer can output multichannel
    audio. Sets the number of stereo channel pairs. So 1 is actually
    2 channels (a stereo pair).</td>
  </tr>

  <tr>
    <td>synth.audio-groups</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>1-128</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Normally the same value as synth.audio-channels. LADSPA
    effects subsystem can use this value though, in which case it may
    differ.</td>
  </tr>

  <tr>
    <td>synth.chorus.active</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1 (TRUE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>When set to 1 (TRUE) the chorus effects module is activated.
    Otherwise, no chorus will be added to the output signal. Note
    that the amount of signal sent to the chorus module depends on the
    "chorus send" generator defined in the SoundFont.</td>
  </tr>

  <tr>
    <td>synth.cpu-cores</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>1-256</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>(Experimental) Sets the number of synthesis CPU cores. If set to a value
    greater than 1, then additional synthesis threads will be created to take
    advantage of a multi CPU or CPU core system. This has the affect of
    utilizing more of the total CPU for voices or decreasing render times
    when synthesizing audio to a file.</td>
  </tr>

  <tr>
    <td>synth.device-id</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>0-126</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Device identifier used for SYSEX commands, such as MIDI
    Tuning Standard commands. Only those SYSEX commands destined
    for this ID or to all devices will be acted upon.</td>
  </tr>

  <tr>
    <td>synth.dump</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0 (FALSE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Does nothing currently.</td>
  </tr>

  <tr>
    <td>synth.effects-channels</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>2</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>2-2</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td></td>
  </tr>

  <tr>
    <td>synth.gain</td>
    <td>Type</td>
    <td>number</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0.2</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>0.0-10.0</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The gain is applied to the final or master output of the
    synthesizer. It is set to a low value by default to avoid the
    saturation of the output when many notes are played.</td>
  </tr>

  <tr>
    <td>synth.ladspa.active</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0 (FALSE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>When set to "yes" the LADSPA subsystem will be enabled. This
    subsystem allows to load and interconnect LADSPA plug-ins. The
    output of the synthesizer is processed by the LADSPA subsystem.
    Note that the synthesizer has to be compiled with LADSPA
    support. More information about the LADSPA subsystem
    later.</td>
  </tr>

  <tr>
    <td>synth.midi-channels</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>16</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>16-256</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>This setting defines the number of MIDI channels of the
    synthesizer. The MIDI standard defines 16 channels, so MIDI
    hardware is limited to this number. Internally FluidSynth can use
    more channels which can be mapped to different MIDI sources.</td>
  </tr>

  <tr>
    <td>synth.midi-bank-select</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>gs</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>gm, gs, xg, mma</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>This setting defines how the synthesizer interprets Bank Select messages.
       <ul>
         <li>gm: ignores CC0 and CC32 messages.</li>
         <li>gs: (default) CC0 becomes the bank number, CC32 is ignored.</li>
         <li>xg: CC32 becomes the bank number, CC0 is ignored.</li>
         <li>mma: bank is calculated as CC0*128+CC32.</li>
       </ul>  
    </td>
  </tr>

  <tr>
    <td>synth.min-note-length</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>10</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>0-65535</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Sets the minimum note duration in milliseconds. This
    ensures that really short duration note events, such as
    percussion notes, have a better chance of sounding as
    intended. Set to 0 to disable this feature.</td>
  </tr>

  <tr>
    <td>synth.parallel-render</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1 (TRUE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>synth.parallel-render is the low-latency setting. If on, you're allowed
to call fluid_synth_write_s16, fluid_synth_write_float,
fluid_synth_nwrite_float or fluid_synth_process in parallel with the
rest of the calls, and it won't be blocked by time intensive calls to
the synth. Turn it off if throughput is more important than latency, e g
in rendering-to-file scenarios where underruns is not an issue.</td>
  </tr>


  <tr>
    <td>synth.polyphony</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>256</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>1-65535</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The polyphony defines how many voices can be played in
    parallel. A note event produces one or more voices.
    Its good to set this to a value which the system can handle
    and will thus limit FluidSynth's CPU usage. When FluidSynth
    runs out of voices it will begin terminating lower priority
    voices for new note events.</td>
  </tr>

  <tr>
    <td>synth.reverb.active</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1 (TRUE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>When set to 1 (TRUE) the reverb effects module is activated.
    Otherwise, no reverb will be added to the output signal. Note
    that the amount of signal sent to the reverb module depends on the
    "reverb send" generator defined in the SoundFont.</td>
  </tr>

  <tr>
    <td>synth.sample-rate</td>
    <td>Type</td>
    <td>number</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>44100</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>22050-96000</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The sample rate of the audio generated by the
    synthesizer.</td>
  </tr>

  <tr>
    <td>synth.threadsafe-api</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>1 (TRUE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>synth.threadsafe-api controls whether the synth's public API is
protected by a mutex or not. Default is on, turn it off for slightly
better performance if you know you're only accessing the synth from one
thread only, this could be the case in many embedded use cases for
example. Note that libfluidsynth can use many threads by itself (shell 
is one, midi driver is one, midi player is one etc) so you should usually 
leave it on. Also see synth.parallel-render.</td>
  </tr>


  <tr>
    <td>synth.verbose</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0 (FALSE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>When set to 1 (TRUE) the synthesizer will print out
    information about the received MIDI events to the stdout. This
    can be helpful for debugging. This setting cannot be changed
    after the synthesizer has started.</td>
  </tr>
</table>

\section CreatingAudioDriver Creating the Audio Driver

The synthesizer itself does not write any audio to the audio output. This allows application developers to manage the audio output themselves if they wish. The next section describes the use of the synthesizer without an audio driver in more detail.

Creating the audio driver is straightforward: set the appropriate settings and create the driver object. Because the FluidSynth has support for several audio systems, you may want to change which one you want to use. The list below shows the audio systems that are currently supported. It displays the name, as used by the fluidsynth library, and a description. 

- jack: JACK Audio Connection Kit (Linux, Mac OS X, Windows)
- alsa: Advanced Linux Sound Architecture (Linux)
- oss: Open Sound System (Linux, Unix)
- pulseaudio: PulseAudio (Linux, Mac OS X, Windows)
- coreaudio: Apple CoreAudio (Mac OS X)
- dsound: Microsoft DirectSound (Windows)
- portaudio: PortAudio Library (Mac OS 9 &amp; X, Windows, Linux)
- sndman: Apple SoundManager (Mac OS Classic)
- dart: DART sound driver (OS/2)
- file: Driver to output audio to a file

The default audio driver depends on the settings with which FluidSynth was compiled. You can get the default driver with fluid_settings_getstr_default(). To get the list of available drivers use the fluid_settings_foreach_option() function. Finally, you can set the driver with fluid_settings_setstr(). In most cases, the default driver should work out of the box. 

Additional options that define the audio quality and latency are "audio.sample-format", "audio.period-size", and "audio.periods". The details are described later. 

You create the audio driver with the new_fluid_audio_driver() function. This function takes the settings and synthesizer object as arguments. For example: 

\code
void init() 
{
    fluid_settings_t* settings;
    fluid_synth_t* synth;
    fluid_audio_driver_t* adriver;
    settings = new_fluid_settings();

    /* Set the synthesizer settings, if necessary */
    synth = new_fluid_synth(settings);

    fluid_settings_setstr(settings, "audio.driver", "jack");
    adriver = new_fluid_audio_driver(settings, synth);
}
\endcode

As soon as the audio driver is created, it will start playing. The audio driver creates a separate thread that uses the synthesizer object to generate the audio.
 
There are a number of general audio driver settings. The audio.driver settings define the audio subsystem that will be used. The audio.periods and audio.period-size settings define the latency and robustness against scheduling delays. There are additional settings for the audio subsystems used which are documented in another table.

<table border="1" cellspacing="0">
  <caption>Table 2. General audio driver settings</caption>
  <tr>
    <td>audio.driver</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>jack (Linux), dsound (Windows), sndman (MacOS9), coreaudio
    (Mac OS X), dart (OS/2)</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>jack, alsa, oss, pulseaudio, coreaudio, dsound, portaudio, sndman, dart, file</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The audio system to be used.</td>
  </tr>

  <tr>
    <td>audio.periods</td>
    <td>Type</td>
    <td>int</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>16 (Linux, Mac OS X), 8 (Windows)</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>2-64</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The number of the audio buffers used by the driver. This
    number of buffers, multiplied by the buffer size (see setting
    audio.period-size), determines the maximum latency of the audio
    driver.</td>
  </tr>

  <tr>
    <td>audio.period-size</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>64 (Linux, Mac OS X), 512 (Windows)</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>64-8192</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The size of the audio buffers (in frames).</td>
  </tr>

  <tr>
    <td>audio.realtime-prio</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>60</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>0-99</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Sets the realtime scheduling priority of the audio synthesis thread
    (0 disables high priority scheduling).  Linux is the only platform which
    currently makes use of different priority levels.  Drivers which use this
    option: alsa, oss and pulseaudio</td>
  </tr>

  <tr>
    <td>audio.sample-format</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"16bits"</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>"16bits", "float"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The format of the audio samples. This is currently only an
    indication; the audio driver may ignore this setting if it
    can't handle the specified format.</td>
  </tr>
</table>


The following table describes audio driver specific settings.

<table border="1" cellspacing="0">
  <caption>Table 3. Audio driver specific settings</caption>
  <tr>
    <td>audio.alsa.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>ALSA device string, such as: "hw:0", "plughw:1", etc.</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Selects the ALSA audio device to use.</td>
  </tr>

  <tr>
    <td>audio.coreaudio.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Selects the CoreAudio device to use.</td>
  </tr>

  <tr>
    <td>audio.dart.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Selects the Dart (OS/2 driver) device to use.</td>
  </tr>

  <tr>
    <td>audio.dsound.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Selects the DirectSound (Windows) device to use.</td>
  </tr>

  <tr>
    <td>audio.file.endian</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>'auto' if libsndfile support is built in, 'cpu' otherwise.</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>auto, big, cpu, little ('cpu' is all that is supported if libsndfile
    support is not built in)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Defines the byte order when using the 'file' driver or file renderer to
    store audio to a file. 'auto' uses the default for the given file type,
    'cpu' uses the CPU byte order, 'big' uses big endian byte order and 'little' uses
    little endian byte order.</td>
  </tr>

  <tr>
    <td>audio.file.format</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>s16</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>double, float, s16, s24, s32, s8, u8 ('s16' is all that is supported if
    libsndfile support not built in)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Defines the audio format when rendering audio to a file. 'double' is
    64 bit floating point, 'float' is 32 bit floating point, 's16' is 16 bit signed
    PCM, 's24' is 24 bit signed PCM, 's32' is 32 bit signed PCM, 's8' is 8 bit
    signed PCM and 'u8' is 8 bit unsigned PCM.</td>
  </tr>

  <tr>
    <td>audio.file.name</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>'fluidsynth.wav' if libsndfile support is built in, 'fluidsynth.raw'
    otherwise.</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Specifies the file name to store the audio to, when rendering audio to
    a file.</td>
  </tr>

  <tr>
    <td>audio.file.type</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>'auto' if libsndfile support is built in, 'raw' otherwise.</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>aiff, au, auto, avr, caf, flac, htk, iff, mat, oga, paf, pvf, raw, sd2, sds,
    sf, voc, w64, wav, xi (actual list of types may vary and depends on the
    libsndfile library used, 'raw' is the only type available if no libsndfile
    support is built in).</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Sets the file type of the file which the audio will be stored to.
    'auto' attempts to determine the file type from the audio.file.name file
    extension and falls back to 'wav' if the extension doesn't match any types.</td>
  </tr>

  <tr>
    <td>audio.jack.autoconnect</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0 (FALSE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>If 1 (TRUE), then FluidSynth output is automatically connected to jack
    system audio output.</td>
  </tr>

  <tr>
    <td>audio.jack.id</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>fluidsynth</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>ID used when creating Jack client connection.</td>
  </tr>

  <tr>
    <td>audio.jack.multi</td>
    <td>Type</td>
    <td>boolean</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>0 (FALSE)</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>If 1 (TRUE), then multi-channel Jack output will be enabled if
    synth.audio-channels is greater than 1.</td>
  </tr>

  <tr>
    <td>audio.jack.server</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Jack server to connect to. Defaults to an empty string, which uses
    default Jack server.</td>
  </tr>

  <tr>
    <td>audio.oss.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>/dev/dsp</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Device to use for OSS audio output.</td>
  </tr>

  <tr>
    <td>audio.portaudio.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>PortAudio Default</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Device to use for PortAudio driver output. Note that 'PortAudio Default'
    is a special value which outputs to the default PortAudio device.</td>
  </tr>

  <tr>
    <td>audio.pulseaudio.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Device to use for PulseAudio driver output</td>
  </tr>

  <tr>
    <td>audio.pulseaudio.server</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Server to use for PulseAudio driver output</td>
  </tr>
</table>

\section UsingSynth Using the synthesizer without an audio driver

It is possible to use the synthesizer object without creating an audio driver. This is desirable if the application using FluidSynth manages the audio output itself. The synthesizer has several API functions that can be used to obtain the audio output: 

fluid_synth_write_s16() fills two buffers (left and right channel) with samples coded as signed 16 bits (the endian-ness is machine dependent). fluid_synth_write_float() fills a left and right audio buffer with 32 bits floating point samples. For multi channel audio output, the function fluid_synth_nwrite_float() has to be used.

The function fluid_synth_process() is still experimental and its use is therefore not recommended but it will probably become the generic interface in future versions. 

\section LoadingSoundfonts Loading and managing SoundFonts

Before any sound can be produced, the synthesizer needs a SoundFont.

SoundFonts are loaded with the fluid_synth_sfload() function. The function takes the path to a SoundFont file and a boolean to indicate whether the presets of the MIDI channels should be updated after the SoundFont is loaded. When the boolean value is TRUE, all MIDI channel bank and program numbers will be refreshed, which may cause new instruments to be selected from the newly loaded SoundFont.

The synthesizer can load any number of SoundFonts. The loaded SoundFonts are treated as a stack, where each new loaded SoundFont is placed at the top of the stack. When selecting presets by bank and program numbers, SoundFonts are searched beginning at the top of the stack. In the case where there are presets in different SoundFonts with identical bank and program numbers, the preset from the most recently loaded SoundFont is used. The fluid_synth_program_select() can be used for unambiguously selecting a preset or bank offsets could be applied to each SoundFont with fluid_synth_set_bank_offset(), to try and ensure that each preset has unique bank and program numbers.

The fluid_synth_sfload() function returns the unique identifier of the loaded SoundFont, or -1 in case of an error. This identifier is used in subsequent management functions: fluid_synth_sfunload() removes the SoundFont, fluid_synth_sfreload() reloads the SoundFont. When a SoundFont is reloaded, it retains it's ID and position on the SoundFont stack.

Additional API functions are provided to get the number of loaded SoundFonts and to get a pointer to the SoundFont. 

\section SendingMIDI Sending MIDI Events

Once the synthesizer is up and running and a SoundFont is loaded, most people will want to do something useful with it. Make noise, for example. MIDI messages can be sent using the fluid_synth_noteon(), fluid_synth_noteoff(), fluid_synth_cc(), fluid_synth_pitch_bend(), fluid_synth_pitch_wheel_sens(), and fluid_synth_program_change() functions. For convenience, there's also a fluid_synth_bank_select() function (the bank select message is normally sent using a control change message). 

The following example show a generic graphical button that plays a note when clicked: 

\code
class SoundButton : public SomeButton
{
public:	

    SoundButton() : SomeButton() {
        if (!_synth) {
            initSynth();
        }
    }

    static void initSynth() {
        _settings = new_fluid_settings();
        _synth = new_fluid_synth(_settings);
        _adriver = new_fluid_audio_driver(_settings, _synth);
    }

    /* ... */

    virtual int handleMouseDown(int x, int y) {
        /* Play a note on key 60 with velocity 100 on MIDI channel 0 */
        fluid_synth_noteon(_synth, 0, 60, 100);
    }

    virtual int handleMouseUp(int x, int y) {
        /* Release the note on key 60 */
        fluid_synth_noteoff(_synth, 0, 60);
    }

protected:

    static fluid_settings_t* _settings;
    static fluid_synth_t* _synth;
    static fluid_audio_driver_t* _adriver;
};
\endcode

\section RealtimeMIDI Creating a Real-time MIDI Driver

FluidSynth can process real-time MIDI events received from hardware MIDI ports or other applications. To do so, the client must create a MIDI input driver. It is a very similar process to the creation of the audio driver: you initialize some properties in a settings instance and call the new_fluid_midi_driver() function providing a callback function that will be invoked when a MIDI event is received. The following MIDI drivers are currently supported:

- jack: JACK Audio Connection Kit MIDI driver (Linux, Mac OS X)
- oss: Open Sound System raw MIDI (Linux, Unix)
- alsa_raw: ALSA raw MIDI interface (Linux)
- alsa_seq: ALSA sequencer MIDI interface (Linux)
- winmidi: Microsoft Windows MM System (Windows)
- midishare: MIDI Share (Linux, Mac OS X)
- coremidi: Apple CoreMIDI (Mac OS X)

\code
#include &lt;fluidsynth.h>

int handle_midi_event(void* data, fluid_midi_event_t* event)
{
    printf("event type: %d\n", fluid_midi_event_get_type(event));
}

int main(int argc, char** argv)
{
    fluid_settings_t* settings;
    fluid_midi_driver_t* mdriver;
    settings = new_fluid_settings();
    mdriver = new_fluid_midi_driver(settings, handle_midi_event, NULL);
    /* ... */    
    delete_fluid_midi_driver(mdriver);
    return 0;
}
\endcode

There are a number of general MIDI driver settings. The midi.driver setting
defines the MIDI subsystem that will be used. There are additional settings for
the MIDI subsystems used, which are described in a following table. 

<table border="1" cellspacing="0">
  <caption>Table 4. General MIDI driver settings</caption>
  <tr>
    <td>midi.driver</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>alsa_seq (Linux), winmidi (Windows), jack (Mac OS X)</td>
  </tr>
  <tr>
    <td></td>
    <td>Options</td>
    <td>alsa_raw, alsa_seq, coremidi, jack, midishare, oss, winmidi</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>The MIDI system to be used.</td>
  </tr>

  <tr>
    <td>midi.realtime-prio</td>
    <td>Type</td>
    <td>integer</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>50</td>
  </tr>
  <tr>
    <td></td>
    <td>Min-Max</td>
    <td>0-99</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Sets the realtime scheduling priority of the MIDI thread
    (0 disables high priority scheduling).  Linux is the only platform which
    currently makes use of different priority levels.  Drivers which use this
    option: alsa_raw, alsa_seq, oss</td>
  </tr>
</table>

The following table defines MIDI driver specific settings.

<table border="1" cellspacing="0">
  <caption>Table 5. MIDI driver specific settings</caption>
  <tr>
    <td>midi.alsa.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>ALSA MIDI device to use for RAW ALSA MIDI driver.</td>
  </tr>

  <tr>
    <td>midi.alsa_seq.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>"default"</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>ALSA sequencer device to use for ALSA sequencer driver.</td>
  </tr>

  <tr>
    <td>midi.alsa_seq.id</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>pid</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>ID to use when registering ports with the ALSA sequencer driver. If
    set to "pid" then the ID will be "FLUID Synth (PID)", where PID is the
    FluidSynth process ID of the audio thread otherwise the provided string
    will be used in place of PID.</td>
  </tr>

  <tr>
    <td>midi.jack.id</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>fluidsynth-midi</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Client ID to use with the Jack MIDI driver.</td>
  </tr>

  <tr>
    <td>midi.jack.server</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Jack server to connect to for Jack MIDI driver. If an empty string then
    the default server will be used.</td>
  </tr>

  <tr>
    <td>midi.oss.device</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td>/dev/midi</td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Device to use for OSS MIDI driver.</td>
  </tr>

  <tr>
    <td>midi.portname</td>
    <td>Type</td>
    <td>string</td>
  </tr>
  <tr>
    <td></td>
    <td>Default</td>
    <td></td>
  </tr>
  <tr>
    <td></td>
    <td>Description</td>
    <td>Used by coremidi and alsa_seq drivers for the portnames registered with
    the MIDI subsystem.</td>
  </tr>
</table>

</doc>
